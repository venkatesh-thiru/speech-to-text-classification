{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to text to classify\n",
    "\n",
    "* For this task we would need a text-to-speech model to convert your voice samples into text\n",
    "* The converted texts are then given to a zero shot text classification model\n",
    "    * which also takes your class queries inputs\n",
    "* The zero shot classifier throws out a class probability score, which you can use as your relevance score\n",
    "\n",
    "\n",
    "\n",
    "Thankfully you dont have to do anything from scratch, all the models you need along with pretrained weights are available in huggingface-transformers library\n",
    "\n",
    "before install transformers library you would need pytorch(also torchaudio), install using the instructions here : https://pytorch.org/get-started/locally/\n",
    "\n",
    "Please install the library, by following the instructions here : https://huggingface.co/docs/transformers/installation\n",
    "\n",
    "once you have these two, you are good to go\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration, pipeline\n",
    "import torchaudio\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\") # model for speech to text\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\") # pre-processor for speech to text model\n",
    "\n",
    "aud = torchaudio.load(\"test_record.wav\") # Your audio file\n",
    "arr = torchaudio.functional.resample(aud[0], orig_freq=aud[1], new_freq=16000) # For some reason ubuntu records at 8000 sample resolution, the model was trained on 16000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venky/.conda/envs/text/lib/python3.10/site-packages/transformers/generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 200 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(arr.squeeze(), sampling_rate = 16000, return_tensors = \"pt\") #Apply the preprocessing to your input\n",
    "\n",
    "generated_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"]) # make predictions\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids, skip_special_tokens = True)[0] # Post process the predictions to readable text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac89a6f6ec0406b8a3dc0003ac2ccd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)e.co/api/models/facebook/bart-large-mnli:   0%|          | 0.00/9.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(model=\"facebook/bart-large-mnli\") # loading the zero-shot text classification pipeline\n",
    "\n",
    "pips = pipe(transcription, candidate_labels = [\"AI\", \"Detection\"], multi_label = True) # make predictions, candidate_labels, are you probable classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'if the detective replied that i used to infer my duty at once', 'labels': ['Detection', 'AI'], 'scores': [0.9030801653862, 0.21847498416900635]}\n"
     ]
    }
   ],
   "source": [
    "print(pips) # your predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
